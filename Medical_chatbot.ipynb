{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7laRuajKGVSS",
        "outputId": "dad33611-0fd2-4679-c805-c97905546f64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.11/dist-packages (6.0.2)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2025.4.26)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone) (4.13.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pinecone"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone\n",
        "\n",
        "pc = Pinecone(\"pcsk_5zSDm7_FiXyttnjXKArVHUKTq2wVnvigTxJD4jQtavV9MJ2kVQbVVjtJuso6pTUkvaJU2W\")\n",
        "\n",
        "# Embed data\n",
        "data = [\n",
        "    {\"id\": \"vec1\", \"text\": \"Apple is a popular fruit known for its sweetness and crisp texture.\"},\n",
        "    {\"id\": \"vec2\", \"text\": \"The tech company Apple is known for its innovative products like the iPhone.\"},\n",
        "    {\"id\": \"vec3\", \"text\": \"Many people enjoy eating apples as a healthy snack.\"},\n",
        "    {\"id\": \"vec4\", \"text\": \"Apple Inc. has revolutionized the tech industry with its sleek designs and user-friendly interfaces.\"},\n",
        "    {\"id\": \"vec5\", \"text\": \"An apple a day keeps the doctor away, as the saying goes.\"},\n",
        "]\n",
        "\n",
        "embeddings = pc.inference.embed(\n",
        "    model=\"llama-text-embed-v2\",\n",
        "    inputs=[d['text'] for d in data],\n",
        "    parameters={\n",
        "        \"input_type\": \"passage\"\n",
        "    }\n",
        ")\n",
        "\n",
        "vectors = []\n",
        "for d, e in zip(data, embeddings):\n",
        "    vectors.append({\n",
        "        \"id\": d['id'],\n",
        "        \"values\": e['values'],\n",
        "        \"metadata\": {'text': d['text']}\n",
        "    })\n",
        "index = pc.Index('llama-text-embed-v2-index')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hIqPZN0IHJ0-"
      },
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] =\"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\""
      ],
      "metadata": {
        "id": "QxRYJQWjMwIj"
      },
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU langchain-groq"
      ],
      "metadata": {
        "id": "4TfsGxbuMCvs"
      },
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_info={\"user_id\":123}"
      ],
      "metadata": {
        "id": "gUz7_LvQmq-7"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "id": "fJxJ-ChDVUEy"
      },
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
        "    ),\n",
        "    (\"human\", \"I love programming.\"),\n",
        "]\n",
        "ai_msg = llm.invoke(messages)\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnjiApNhGiOG",
        "outputId": "2bb1ab54-4fc1-438c-a354-467fce7fc9ca"
      },
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The translation of \"I love programming\" to French is:\n",
            "\n",
            "\"J'adore le programmation.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "controller_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"\n",
        "You are a controller agent for a medical chatbot. Your job is to decide which of the following agents should handle the user query:\n",
        "\n",
        "- Response_agent: Use this for general medical questions that do not require any personal user information. For example, if the user asks for general facts or opinions unrelated to their personal condition or history.\n",
        "\n",
        "- retriever_agent: Use this when the user asks for medical advice or recommendations that depend on their personal data. If the user's own health, symptoms, or history are relevant, select this agent.\n",
        "\n",
        "Reply with only one of the following:\n",
        "- Response_agent\n",
        "- retriever_agent\n",
        "\"\"\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\")  # This is the correct role for tool responses or internal reasoning\n",
        "])\n"
      ],
      "metadata": {
        "id": "O61ZGiXzV3u8"
      },
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_tool_calling_agent\n",
        "tools=[]\n",
        "\n",
        "controller_agent = create_tool_calling_agent(llm, tools=tools,prompt=controller_prompt)"
      ],
      "metadata": {
        "id": "-s-LlixpXpM_"
      },
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"\n",
        "You are a response agent for a medical chatbot. Your job is to give an appopriate response to the user's medical query. If the user's prompt is not medical related that do not answer and just reply that you are a medical chatbot.\n",
        "\"\"\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\")  # This is the correct role for tool responses or internal reasoning\n",
        "])"
      ],
      "metadata": {
        "id": "wu3jpUHhfMUT"
      },
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_agent = create_tool_calling_agent(llm, tools=tools,prompt=response_prompt)"
      ],
      "metadata": {
        "id": "THFpHDOYgEkm"
      },
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "\n",
        "\n",
        "\n",
        "def RAG_Agent(user_prompt):\n",
        "  data={\"id\":user_info['user_id'],\"text\":user_prompt}\n",
        "  x = pc.inference.embed(\n",
        "    model=\"llama-text-embed-v2\",\n",
        "    inputs=[user_prompt],\n",
        "    parameters={\n",
        "        \"input_type\": \"query\"\n",
        "    })\n",
        "\n",
        "  vectors = []\n",
        "  new_id = str(uuid.uuid4())\n",
        "\n",
        "  vectors.append({\n",
        "        \"id\": new_id,\n",
        "        \"values\": e['values'],\n",
        "        \"metadata\": {'user_id':user_info['user_id'],'text':user_prompt}\n",
        "    })\n",
        "  results = index.query(\n",
        "    namespace=\"ns1\",\n",
        "    vector=x[0].values,\n",
        "    top_k=3,\n",
        "    include_values=False,\n",
        "    include_metadata=True,\n",
        "    filter={\"user_id\":123} )\n",
        "  if results[\"matches\"]:\n",
        "    return results\n",
        "  else:\n",
        "    return \"None\"\n",
        "\n",
        "results=RAG_Agent(user_query)\n",
        "if results!=\"None\":\n",
        "  context_texts = [match['metadata']['text'] for match in results['matches']]\n",
        "  combined_context = \"\\n\".join(context_texts)\n",
        "  formatted_input = f\"user: {user_query}\\ncontext: {combined_context}\"\n",
        "else:\n",
        "  formatted_input = f\"user: {user_query}\\ncontext:None\"\n",
        "print(formatted_input)\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_bNjJlMiZs7",
        "outputId": "90570bd3-6adf-4f6b-f290-a2a8e9f4d241"
      },
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user: My nose is bleeding\n",
            "context:None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "context_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"\n",
        "You are a checker agent for a medical chatbot.\n",
        "\n",
        "A Retrieval-Augmented Generation (RAG) system has fetched the top context documents for a given user query. If no context was fetched than context will be False\n",
        "Your task is to review the query and the retrieved context, then determine whether additional information is needed from the user.\n",
        "\n",
        "If the current context is not sufficient to answer the user's question accurately, respond by listing the specific missing information you would ask the user for.\n",
        "\n",
        "If the context is sufficient, respond with:\n",
        "\"Sufficient\"\n",
        "\n",
        "The input format is as follows:\n",
        "user: <user_query>\n",
        "context: <retrieved_context>or None if no context\n",
        "\n",
        "\n",
        "\"\"\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\")\n",
        "])\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "CMZMmpOr0jKD"
      },
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_agent = create_tool_calling_agent(llm, tools=tools,prompt=context_prompt)"
      ],
      "metadata": {
        "id": "zhNizgfa6G8J"
      },
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "control_agent_executor = AgentExecutor(agent=controller_agent, tools=tools, verbose=True)\n",
        "\n",
        "response_agent_executor = AgentExecutor(agent=response_agent, tools=tools, verbose=True)\n",
        "\n",
        "context_agent_executor = AgentExecutor(agent=context_agent, tools=tools, verbose=True)"
      ],
      "metadata": {
        "id": "NLCw-IyDbVEB"
      },
      "execution_count": 281,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_query=\"My nose is bleeding\"\n",
        "selected_agent=agent_executor.invoke({\"input\":user_query})\n",
        "selected_agent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LvzaXzobouu",
        "outputId": "a2650fae-683e-4fbb-c588-4bfc921f476e"
      },
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mretriever_agent\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'My nose is bleeding', 'output': 'retriever_agent'}"
            ]
          },
          "metadata": {},
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(selected_agent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_b_7F90hv5O",
        "outputId": "e78aa7c5-c611-4cc4-d455-924e8384b434"
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': 'My nose is bleeding', 'output': 'retriever_agent'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if selected_agent['output'] == \"Response_agent\":\n",
        "    result = response_agent_executor.invoke({\"input\": user_query})\n",
        "else:\n",
        "  results=RAG_Agent(user_query)\n",
        "  formatted_query=''\n",
        "  if results!=\"None\":\n",
        "    context_texts = [match['metadata']['text'] for match in results['matches']]\n",
        "    combined_context = \"\\n\".join(context_texts)\n",
        "    formatted_query = f\"user: {user_query}\\ncontext: {combined_context}\"\n",
        "  else:\n",
        "    formatted_query = f\"user: {user_query}\\ncontext:None\"\n",
        "  print(formatted_query)\n",
        "  contexts=context_agent_executor.invoke({\"input\":formatted_query})\n",
        "  context=''\n",
        "  if contexts['output']!='Sufficient':\n",
        "    context=input()\n",
        "  final_query=user_query+formatted_query+context\n",
        "  result = response_agent_executor.invoke({\"input\":final_query})\n",
        "  result['output']\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DglHcucKgxHo",
        "outputId": "206e0846-28f2-4c0b-af88-9dd809ea1cfb"
      },
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user: My nose is bleeding\n",
            "context:None\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need more information to provide an accurate response. Please provide the following details:\n",
            "\n",
            "1. How long has your nose been bleeding?\n",
            "2. Is the bleeding heavy or light?\n",
            "3. Have you experienced any trauma or injury to your nose recently?\n",
            "4. Do you have any underlying medical conditions, such as high blood pressure or bleeding disorders?\n",
            "5. Have you taken any medications recently that may be causing the bleeding?\n",
            "\n",
            "Once I have this information, I can better assist you.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "skss\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mA nosebleed can be caused by several factors, including dry air, blowing your nose too hard, or an injury to the nose. To stop the bleeding, try the following steps:\n",
            "\n",
            "1. Sit up straight and lean forward to prevent blood from flowing down the back of your throat.\n",
            "2. Pinch the soft part of your nose shut with your thumb and index finger for 5-10 minutes. This will help to constrict the blood vessels and stop the bleeding.\n",
            "3. Apply gentle pressure to the bridge of your nose with a clean cloth or gauze for a few minutes.\n",
            "4. If the bleeding doesn't stop after 10-15 minutes, you can try using a nasal spray that contains oxymetazoline or phenylephrine to help constrict the blood vessels.\n",
            "5. If the bleeding is heavy or doesn't stop after 30 minutes, seek medical attention.\n",
            "\n",
            "It's also a good idea to stay calm and avoid picking or blowing your nose until the bleeding has stopped.\n",
            "\n",
            "If you experience any of the following symptoms, seek medical attention immediately:\n",
            "\n",
            "- Heavy bleeding that doesn't stop after 30 minutes\n",
            "- Difficulty breathing\n",
            "- Severe pain or swelling in the face\n",
            "- A nosebleed that occurs frequently or is severe\n",
            "\n",
            "Please note that if you have a pre-existing medical condition or are taking any medications, you should consult with your doctor before trying any remedies for a nosebleed.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}